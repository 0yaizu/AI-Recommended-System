import io, requests, json, re, time, base64, qrcode
from PIL import Image
import google.generativeai as genai
import streamlit as st
from bs4 import BeautifulSoup
from jsonc_parser.parser import JsoncParser

# Load config.json file
def load_config():
	with open('./config.json', 'r', encoding="utf-8") as f:
		text = f.read()
		config_obj = JsoncParser.parse_str(text)
	return config_obj

# Load the .env file
import import_settings

# Set the Gemini API key
genai.configure(api_key=import_settings.gemini_api)

def vvox_test(text):
	# ã‚¨ãƒ³ã‚¸ãƒ³èµ·å‹•æ™‚ã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹IPã€portã‚’æŒ‡å®š
	host = import_settings.voicevox_host
	port = import_settings.voicevox_port

	# éŸ³å£°åŒ–ã™ã‚‹æ–‡è¨€ã¨è©±è€…ã‚’æŒ‡å®š(3ã§æ¨™æº–ãšã‚“ã ã‚‚ã‚“ã«ãªã‚‹)
	params = (
		('text', text),
		('speaker', 3),
	)

	# éŸ³å£°åˆæˆç”¨ã®ã‚¯ã‚¨ãƒªä½œæˆ
	query = requests.post(
		f'http://{host}:{port}/audio_query',
		params=params
	)

	# éŸ³å£°åˆæˆã‚’å®Ÿæ–½
	synthesis = requests.post(
		f'http://{host}:{port}/synthesis',
		headers = {"Content-Type": "application/json"},
		params = params,
		data = json.dumps(query.json())
	)

	# å†ç”Ÿå‡¦ç†
	voice = synthesis.content
	return voice

st.set_page_config(page_title="ä»Šé€±ã®ãŠã™ã™ã‚å•†å“", page_icon="ğŸ‰", layout="centered")

def main():
	# Streamlit
	st.title("ä»Šé€±ã®ãŠã™ã™ã‚å•†å“")

	config = load_config()
	res = requests.get(config["loading_page"])
	res.encoding = res.apparent_encoding
	soup = BeautifulSoup(res.text, 'html.parser')

	product_img = st.empty()
	st.text("â€»å•†å“ç´¹ä»‹ã®éŸ³å£°ã¯ã€ç”»åƒã‚’å…ƒã«AIã‚’ç”¨ã„ã¦ç”Ÿæˆã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã™ã¹ã¦ãŒæ­£ã—ã„æƒ…å ±ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚è©³ã—ã„èª¬æ˜ã¯åº—é ­ã®ã‚¹ã‚¿ãƒƒãƒ•ã«ãŠå°‹ã­ãã ã•ã„ã€‚")
	img_byte_array = io.BytesIO()
	qrimg = qrcode.make(config["mobile_qr"])
	qrimg.save(img_byte_array, format='PNG')
	_, qr_stimg, _ = st.columns([1, 3, 1])
	with qr_stimg:
		st.image(img_byte_array, width=500)
	st.title("â†‘ãƒ¢ãƒã‚¤ãƒ«ä¼šå“¡ã®ã”ç™»éŒ²ã¯ã“ã¡ã‚‰â†‘")
	while True:
		for img_link in (soup.find('div', {'class': 'wsprd_row wsprd_row-2'}).find_all('img')):
			img_src = config["loading_page"] + img_link.get('src')[2:]
			img = Image.open(io.BytesIO(requests.get(img_src).content))
			model = genai.GenerativeModel("gemini-1.5-flash")
			update_config = load_config()
			prompt = update_config["prompt"]
			response = model.generate_content([prompt, img])
			time.sleep(2)
			# ç”»åƒèªè­˜ã€èª¬æ˜æ–‡ç”Ÿæˆã€éŸ³å£°å‡ºåŠ›
			content = vvox_test(response.text)
			audio_str = "data:audio/ogg;base64,%s"%(base64.b64encode(content).decode())
			audio_html = """
				<audio autoplay=True>
				<source src="%s" type="audio/ogg" autoplay=True>
				Your browser does not support the audio element.
				</audio>
				"""%audio_str

			product_img.write(img)
			audio_placeholder = st.empty()
			audio_placeholder.empty()
			time.sleep(0.5)
			audio_placeholder.markdown(audio_html, unsafe_allow_html=True)
			time.sleep(60)

	# for img in (soup.find('div', {'class': 'wsprd_row wsprd_row-2'}).find_all('img')):
	# 	img_src = config["loading_page"] + img.get('src')[2:]

	# 	print(img_src)
	# 	img = Image.open(io.BytesIO(requests.get(img_src).content))

	# 	model = genai.GenerativeModel("gemini-1.5-flash")
	# 	prompt = "ã‚ãªãŸã¯å•†å“ã®è²©å£²å“¡ã§ã™ã€‚ã“ã®å•†å“ã«ã¤ã„ã¦ã€ãŠå®¢æ§˜ã«è©±ã™ã‚ˆã†ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€ãƒã‚¤ãƒ³ãƒˆé‚„å…ƒã¨ã„ã†ã®ã¯å•†å“ã®æ–™é‡‘ã«åˆã—ã¦ãƒã‚¤ãƒ³ãƒˆã‚’ãŠä»˜ã‘ã™ã‚‹ã¨ã„ã†ã‚‚ã®ã§ã™ã€‚TTSç”¨ã«èªè­˜ã•ã›ã‚„ã™ã„å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚100æ–‡å­—ä»¥ä¸Šã€200æ–‡å­—ä»¥ä¸‹ã§ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
	# 	response = model.generate_content([prompt, img_src])
	# 	vvox_test(response.text)
	# 	print(response.text)

	# 	time.sleep(60)

if __name__ == "__main__":
	main()